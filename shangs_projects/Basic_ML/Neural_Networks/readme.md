# Neural Network

This is an exercise in building a neural network from scratch and training it using a randomly generated set of data.

Neural network details:
 - 1 hidden layer with 50 nodes
 - Sigmoid activation function
 - Cross entropy cost function
 - L2 regularization
 - 2000 training samples with 2 output classes used for training
 - Mini-batch gradient descent of 200 random samples per iteration used for training

## Results

The following animation shows the evolution of the decision boundary of the neural network after X iterations.

![boundary](https://github.com/iamshang1/Projects/blob/master/Basic_ML/Neural_Networks/boundary.gif)