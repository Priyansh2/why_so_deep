from pyspark.sql import SparkSession
from pyspark.ml.linalg import SparseVector, VectorUDT, Vectors
from pyspark.sql.types import *
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.feature import ChiSqSelector
from pyspark.ml.classification import RandomForestClassifier
from preprocessing_bytes import preprocessor_bytes
from preprocessing_asm import preprocessor_asm

#initialize spark session
spark = SparkSession\
        .builder\
        .appName("Malware Random Forests")\
        .getOrCreate()
sc = spark.sparkContext

#paths to training data
X_file = "./data/X_train.txt"
y_file = "./data/y_train.txt"
X_file = sc.textFile(X_file,80)
y_file = sc.textFile(y_file,80)

#get train bytes features
preprocessor_b = preprocessor_bytes()
train_bytes = preprocessor_b.transform(X_file,y_file)

#get asm features
preprocessor_a = preprocessor_asm()
train_asm = preprocessor_a.transform(X_file,y_file)

#paths to test data
X_file = "./data/X_test.txt"
X_file = sc.textFile(X_file,80)

#get test bytes data
test_bytes = preprocessor_b.transform(X_file)

#get test asm data
test_asm = preprocessor_a.transform(X_file,train=False)

#chisqr feature selector
selector1 = ChiSqSelector(numTopFeatures=150, outputCol="selectedFeatures")
selectormodel1 = selector1.fit(train_bytes)
train_bytes = selectormodel1.transform(train_bytes)
test_bytes = selectormodel1.transform(test_bytes)

selector2 = ChiSqSelector(numTopFeatures=150, outputCol="selectedFeatures")
selectormodel2 = selector2.fit(train_asm)
train_asm = selectormodel2.transform(train_asm)
test_asm = selectormodel2.transform(test_asm)

#to rdd
train_bytes = train_bytes.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))
test_bytes = test_bytes.select('hash','selectedFeatures').rdd
train_asm = train_asm.select('hash','selectedFeatures','label').rdd.map(lambda (hash,feats,label):(hash,(feats,label)))
test_asm = test_asm.select('hash','selectedFeatures').rdd

#merge bytes and asm data
train = train_bytes.join(train_asm).map(lambda (hash,((bytes,label1),(asm,label2))): (hash,bytes,asm,label1))
test = test_bytes.join(test_asm).map(lambda (hash,(bytes,asm)): (hash,bytes,asm))
schema_train = StructType([StructField('hash',StringType(),True),StructField('bytes',VectorUDT(),True),StructField('asm',VectorUDT(),True),StructField('label',StringType(),True)])
schema_test = StructType([StructField('hash',StringType(),True),StructField('bytes',VectorUDT(),True),StructField('asm',VectorUDT(),True)])
train = train.toDF(schema_train)
train = train.withColumn('label',train.label.cast(DoubleType()))
test = test.toDF(schema_test)
            
#merge bytes and asm features
assembler = VectorAssembler(inputCols=["bytes", "asm"],outputCol="features")
train = assembler.transform(train)
test = assembler.transform(test)

#rf classifier
rf = RandomForestClassifier(numTrees=100,maxDepth=12,maxBins=32,maxMemoryInMB=512,seed=1)
model = rf.fit(train)
result = model.transform(test)

#save to csv
result.select("hash","prediction").toPandas().to_csv('prediction.csv',header=False,index=False)

spark.stop()
